{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vAwHjiCoj8A"
      },
      "source": [
        "Import All required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM3qKKNjD7mi",
        "outputId": "4a7490ba-90b0-4586-e5cd-a932fb832063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pytorch Version: 2.6.0+cu124\n",
            "Torchvision Version: 0.21.0+cu124\n",
            "Device Type: cuda\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# Basic Setup\n",
        "#pytorch\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "#torchvision\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import MobileNet_V2_Weights\n",
        "\n",
        "#misc\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "#plotting\n",
        "import matplotlib.pyplot as plt\n",
        "print(f\"Pytorch Version: {torch.__version__}\")\n",
        "print(f\"Torchvision Version: {torchvision.__version__}\")\n",
        "\n",
        "#Device agnostic\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device Type: {device}\")\n",
        "\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5EhzOQJILL7"
      },
      "source": [
        "Setup WandB connection with API key ❗**REMOVE API KEY IF PUBLISHED** ❗\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0xi1AP8L62OM",
        "outputId": "96150b78-4fd5-4aa4-d330-bf68155c4d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.8)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.23.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maweismann\u001b[0m (\u001b[33mcic-truthseeker\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install --upgrade wandb\n",
        "import wandb\n",
        "key = \"\"\n",
        "wandb.login(key=key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Y96TVpd4QH"
      },
      "source": [
        "## CHANGE THESE EVERY RUN:\n",
        "---\n",
        "* config -> architecture\n",
        "* train_data_dir -> location\n",
        "* test_data_dir -> location\n",
        "* augmented_data_dir -> change drive location to the test type\n",
        "* train_dataset_augmented -> update location\n",
        "* test_dataset_augmented -> update location\n",
        "\n",
        "~test~\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "UB5lIFbNjR5o",
        "outputId": "de1268cc-9202-4031-f7d0-eb9440c8d852"
      },
      "outputs": [],
      "source": [
        "# Initialize W&B\n",
        "wandb.init(\n",
        "    settings=wandb.Settings(init_timeout=90),\n",
        "    project=\"Synthetic-Data-Augmentation-Base\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"batch_size\": 8,\n",
        "        \"epochs\": 15,\n",
        "        \"architecture\": \"MobileNetV2\",\n",
        "        \"image_size\": 224,\n",
        "        \"k_folds\": 5,\n",
        "    },\n",
        ")\n",
        "config = wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKB3Gx3YIaxQ"
      },
      "source": [
        "Create the transforms and augment the original data. Creating a new dataset that contains the transformed images in it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_ivEcc_ujZe"
      },
      "outputs": [],
      "source": [
        "# pre augment the training data to create additional images for the dataset\n",
        "train_data_dir = \"/content/drive/MyDrive/exp5/train\"\n",
        "test_data_dir = \"/content/drive/MyDrive/exp5/test\"\n",
        "\n",
        "#transforms\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.Resize((config['image_size'],config['image_size'])),\n",
        "    transforms.RandomRotation(degrees= 10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((config['image_size'], config['image_size'])),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomResizedCrop(config['image_size'], scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((config['image_size'], config['image_size'])),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ixT0OHnjLjr",
        "outputId": "c84e241a-4d91-41ea-9274-92efd56af344"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 252/252 [01:04<00:00,  3.92it/s]\n",
            "100%|██████████| 252/252 [01:11<00:00,  3.54it/s]\n",
            "100%|██████████| 251/251 [01:08<00:00,  3.67it/s]\n",
            "100%|██████████| 249/249 [01:06<00:00,  3.72it/s]\n"
          ]
        }
      ],
      "source": [
        "# created augmented data directory for future use\n",
        "for dir in [train_data_dir,test_data_dir]:\n",
        "  os.makedirs(f\"/content/drive/MyDrive/exp5/augmented_{os.path.basename(dir)}\",exist_ok= True)\n",
        "  for label_folder in os.listdir(dir):\n",
        "    original_folder = os.path.join(dir,label_folder)\n",
        "\n",
        "    augmented_folder_path = os.path.join(f\"/content/drive/MyDrive/exp5/augmented_{os.path.basename(dir)}\",label_folder)\n",
        "    os.makedirs(augmented_folder_path,exist_ok=True)\n",
        "\n",
        "    for image_name in tqdm(os.listdir(original_folder)):\n",
        "      image_path = os.path.join(original_folder,image_name)\n",
        "      image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "      for i in range(5):\n",
        "        augmented_image = augmentation_transform(image)\n",
        "        augmented_image_path = os.path.join(augmented_folder_path,f\"{os.path.splitext(image_name)[0]}_aug_{i}.png\")\n",
        "        transforms.ToPILImage()(augmented_image).save(augmented_image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNqkb_lWIyJL"
      },
      "source": [
        "Define the SytheticDataset class for use later when loading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwg6nYFBjeXD"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class\n",
        "class SyntheticDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Traverse 'hybrid' and 'local' subdirectories\n",
        "        for label_folder in ['hybrid', 'local']:\n",
        "            folder_path = os.path.join(data_dir, label_folder)\n",
        "            label = 1 if label_folder == 'hybrid' else 0  # 1 for hybrid, 0 for local\n",
        "\n",
        "            for image_name in os.listdir(folder_path):\n",
        "                image_path = os.path.join(folder_path, image_name)\n",
        "                self.image_paths.append(image_path)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.float32)  # For BCEWithLogitsLoss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD9kuLKfI9TK"
      },
      "source": [
        "Create two datasets:\n",
        "\n",
        "*   Base dataset train and test splits\n",
        "*   Augmented data train and test splits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmww62gAjXgl",
        "outputId": "d98a18ce-b5b4-43d4-ecfd-b8b523ff3668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Train Size: 504 || Augmented Train Size: 2520\n",
            "Original Test Size: 500 || Augmented Test Size: 2500\n"
          ]
        }
      ],
      "source": [
        "train_dataset_original = SyntheticDataset(data_dir= train_data_dir,transform= train_transform)\n",
        "test_dataset_original = SyntheticDataset(data_dir= test_data_dir, transform= test_transform)\n",
        "\n",
        "train_dataset_augmented = SyntheticDataset(data_dir= \"/content/drive/MyDrive/exp5/augmented_train\", transform= train_transform)\n",
        "test_dataset_augmented = SyntheticDataset(data_dir= \"/content/drive/MyDrive/exp5/augmented_test\", transform= test_transform)\n",
        "\n",
        "print(f\"Original Train Size: {len(train_dataset_original)} || Augmented Train Size: {len(train_dataset_augmented)}\")\n",
        "print(f\"Original Test Size: {len(test_dataset_original)} || Augmented Test Size: {len(test_dataset_augmented)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gGXsXlpZ2vX",
        "outputId": "83815009-46d4-4359-e547-5a1e727eb634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overlap between training and validation sets: 0 samples\n"
          ]
        }
      ],
      "source": [
        "# train_idx_set = set(train_idx)\n",
        "# val_idx_set = set(val_idx)\n",
        "# overlap = train_idx_set.intersection(val_idx_set)\n",
        "\n",
        "# print(f\"Overlap between training and validation sets: {len(overlap)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jnXXTExkT6DV",
        "outputId": "bd568fed-8ced-44d0-85e9-1ad28a265734"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from torchvision import models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = train_dataset_augmented\n",
        "test_dataset = test_dataset_augmented\n",
        "\n",
        "# ================================\n",
        "# K-Fold Cross-Validation Setup\n",
        "# ================================\n",
        "k_folds = config.k_folds\n",
        "kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "train_labels = [label for _, label in train_dataset]\n",
        "\n",
        "\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "\n",
        "fold_results = []  # Store per-fold metrics\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(indices,train_labels)):\n",
        "    print(f\"\\n===== Fold {fold + 1}/{k_folds} =====\")\n",
        "\n",
        "    # Create Subsets and DataLoader\n",
        "    train_subset = torch.utils.data.Subset(train_dataset, train_idx)\n",
        "    val_subset = torch.utils.data.Subset(train_dataset, val_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=config.batch_size, shuffle= True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=config.batch_size, shuffle= True)\n",
        "\n",
        "\n",
        "    # ==============  Model Setup (Change if needed) ================\n",
        "    model = models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Freeze all layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # # unfreeze the last 5 layers\n",
        "    for param in model.features[-5:].parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    # Unfreeze the classifier layer\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.7), # we can change the dropout layer here's percentage also\n",
        "        nn.Linear(model.last_channel, 1)\n",
        "    )\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    # criterion and optimizer init\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
        "\n",
        "    # ====================\n",
        "    # Training the Fold\n",
        "    # ====================\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct_train = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            preds = torch.sigmoid(outputs).round()\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "        # Average training loss and accuracy\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100.0 * correct_train / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "        # Validation on the Fold\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images).squeeze(-1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                preds = torch.sigmoid(outputs).round()\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # Average validation loss and accuracy\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = 100.0 * correct_val / len(val_loader.dataset)\n",
        "\n",
        "        # Additional metrics\n",
        "        precision = precision_score(all_labels, all_preds, average='binary', zero_division=1)\n",
        "        recall = recall_score(all_labels, all_preds, average='binary', zero_division=1)\n",
        "        f1 = f1_score(all_labels, all_preds, average='binary', zero_division=1)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            \"fold\": fold + 1,\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_accuracy,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_accuracy,\n",
        "            \"val_precision\": precision,\n",
        "            \"val_recall\": recall,\n",
        "            \"val_f1\": f1,\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        })\n",
        "\n",
        "    # Store final fold metrics (from the last epoch)\n",
        "    fold_results.append([val_accuracy, precision, recall, f1])\n",
        "    print(f\"Fold {fold+1} Results - Accuracy: {val_accuracy:.2f}%, Precision: {precision:.4f}, \"\n",
        "          f\"Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "avg_metrics = np.mean(fold_results, axis=0)\n",
        "print(\"\\n===== Final K-Fold Results =====\")\n",
        "print(f\"Avg Accuracy: {avg_metrics[0]:.2f}%, Avg Precision: {avg_metrics[1]:.4f}, \"\n",
        "      f\"Avg Recall: {avg_metrics[2]:.4f}, Avg F1: {avg_metrics[3]:.4f}\")\n",
        "\n",
        "# ========================\n",
        "# Final Evaluation on Test\n",
        "# ========================\n",
        "print(\"\\n===== Final Evaluation on Test Set =====\")\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct_test = 0\n",
        "all_test_labels = []\n",
        "all_test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images).squeeze(-1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "        preds = torch.sigmoid(outputs).round()\n",
        "        correct_test += (preds == labels).sum().item()\n",
        "        all_test_labels.extend(labels.cpu().numpy())\n",
        "        all_test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_accuracy = 100.0 * correct_test / len(test_loader.dataset)\n",
        "\n",
        "test_precision = precision_score(all_test_labels, all_test_preds, average='binary', zero_division=1)\n",
        "test_recall = recall_score(all_test_labels, all_test_preds, average='binary', zero_division=1)\n",
        "test_f1 = f1_score(all_test_labels, all_test_preds, average='binary', zero_division=1)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1: {test_f1:.4f}\")\n",
        "\n",
        "wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
